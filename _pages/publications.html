---
layout: default
title: Publications - Huiyuan Lai
permalink: publications.html
---

<div class="well">

<h2>2021</h2>

   <ul>
       <li><strong>Human Perception in Natural Language Generation.</strong>
           Lorenzo De Mattei, Huiyuan Lai, Felice Dell’Orletta, Malvina Nissim.
           In Proceedings of the 1st Workshop on Generation Evaluation and Metrics (GEM), Association for Computational Linguistics, 2021.
           [<a href="javascript:copy(div0, bib0)">bib</a>]
           [<a href="https://pure.rug.nl/ws/portalfiles/portal/173139255/5_Paper.pdf" target="_blank"> pdf</a>]</li>
           <div id="div0"></div><div id="bib0" style="display:none">
           <div class="bib">
           <pre>
           @inproceedings{6841d01db1c54f169e0a8c6bf0986fa4,
              title = "Human Perception in Natural Language Generation",
              author = "{de Mattei}, Lorenzo and Huiyuan Lai and Felice Dell'Orletta and Malvina Nissim",
              year = "2021",
              language = "English",
              booktitle = "Proceedings of the 1st Workshop on Generation Evaluation and Metrics",
              publisher = "Association for Computational Linguistics, ACL Anthology",
          }
          </pre>
          </div>
          </div>
   </ul>

   <ul>
       <li><strong>Thank you BART! Rewarding Pre-Trained Models Improves Formality Style Transfer.</strong>
           Huiyuan Lai, Antonio Toral and Malvina Nissim.
           The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on           Natural Language Processing (ACL-IJCNLP 2021).
           [<a href="javascript:copy(div1, bib1)">bib</a>]
           [<a href="https://arxiv.org/pdf/2105.06947.pdf" target="_blank"> PDF</a>]
           [<a href="https://github.com/laihuiyuan/Pre-trained-formality-transfer" target="_blank"> CODE</a>]</li>
           <div id="div1"></div><div id="bib1" style="display:none">
           <div class="bib">
           <pre>
           @article{DBLP:journals/corr/abs-2105-06947,
               author    = {Huiyuan Lai and Antonio Toral and Malvina Nissim},
               title     = {Thank you BART! Rewarding Pre-Trained Models Improves Formality Style Transfer},
               volume    = {abs/2105.06947},
               year      = {2021},
               url       = {https://arxiv.org/abs/2105.06947},
               archivePrefix = {arXiv},
               eprint    = {2105.06947},
          }
          </pre>
          </div>
          </div>
   </ul>

<h2>2020</h2>

   <ul>
       <li><strong>On the interaction of automatic evaluation and task framing in headline style transfer.</strong>
           Lorenzo De Mattei, Michele Cafagna, Huiyuan Lai, Felice Dell’Orletta, Malvina Nissim and Albert Gatt. 
           In Proceedings of the 1st Workshop on Evaluating NLG Evaluation (EvalNLGEval'20), Association for Computational Linguistics, 2020.
           [<a href="https://arxiv.org/pdf/2101.01634.pdf" target="_blank"> PDF</a>] </li>
   </ul>

<h2>2019</h2>
   <ul>
       <li><strong>Bi-Directional Attention Comparison for Semantic Sentence Matching.</strong> 
            Huiyuan Lai, Yizheng Tao, Chunliu Wang, Lunfan Xu, Dingyong Tang, Gongliang Li. 
            Multimedia Tools and Applications, 2019. </li>
   </ul>

   <ul>
       <li><strong>开放域对话系统的自动化评测方法研究.</strong>
           王春柳, 杨永辉, 赖辉源.
           计算机应用研究, 2019. </li>
   </ul>

<h2>2018</h2>
    <ul>
        <li><strong>A Deep Architecture for Chinese Semantic Matching with Pairwise Comparisons and Attention-Pooling.</strong>
            Huiyuan Lai, Yizheng Tao, Chunliu Wang, Lunfan Xu, Dingyong Tang, Gongliang Li. 
            International Symposium on Artificial Intelligence and Robotics, 2018. </li>
    </ul>
</div>
